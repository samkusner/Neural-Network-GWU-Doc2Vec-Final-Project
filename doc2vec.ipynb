{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\adham\\Documents\\CSCI 4366\\doc2vec-keras-ap-jr-sk\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Current imports\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "##Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Input, Flatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Read in CSV\n",
    "df = pd.read_csv('IMDB_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: sentiment, dtype: int64\n",
      "0    One of the other reviewers has mentioned that ...\n",
      "1    A wonderful little production. <br /><br />The...\n",
      "2    I thought this was a wonderful way to spend ti...\n",
      "3    Basically there's a family where a little boy ...\n",
      "4    Petter Mattei's \"Love in the Time of Money\" is...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "y=df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "##turn string negative to positive into binary classification\n",
    "print(y.head())\n",
    "\n",
    "reviews=df['review']\n",
    "print(reviews.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preprocessing libraries\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preprocessing code\n",
    "##remove stop words? ##negligible\n",
    "##lowercase or standardize the format or each word? ## case sensitivity might matter in sentiment analysis\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "word_index = tokenizer.word_index\n",
    "padded_sequences = pad_sequences(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ...   125  4103   486]\n",
      " [    0     0     0 ...  1977    69   221]\n",
      " [    0     0     0 ...    63    16   350]\n",
      " ...\n",
      " [    0     0     0 ... 22840     2  6050]\n",
      " [    0     0     0 ...    67   739    42]\n",
      " [    0     0     0 ...   794    11    17]]\n",
      "(50000, 2493)\n"
     ]
    }
   ],
   "source": [
    "print(padded_sequences)\n",
    "print(padded_sequences.shape)\n",
    "##50,000 sequences padded to a length of 2493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Experiment with this\n",
    "EMBEDDING_DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 2493), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\")\n"
     ]
    }
   ],
   "source": [
    "##Testing environment\n",
    "print(Input(shape=(padded_sequences.shape[1],)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec_model():\n",
    "    \n",
    "    ##We have a 2D representation for the tensor, reduce to 1D which is what we need\n",
    "    ##first dimension will have variable size and second dimension is 2493\n",
    "\n",
    "    input_layer = Input(shape=(padded_sequences.shape[1],))\n",
    "\n",
    "\n",
    "    #Embedding layer\n",
    "    ##word_index is a dictionary, add +1 for the padding token\n",
    "    embedding_layer = Embedding(input_dim=len(word_index) + 1, output_dim=EMBEDDING_DIM)(input_layer)\n",
    "\n",
    "    #GlobalAveragePooling1D layer\n",
    "    ##average_pooling = GlobalAveragePooling1D()(embedding_layer)\n",
    "\n",
    "    #Flattening\n",
    "    flatten = Flatten()(embedding_layer)\n",
    "\n",
    "\n",
    "    #Dense layers\n",
    "    #Optimization such as dropout??\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid')(flatten)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    #binary or multi-class compilation\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 305s 61ms/step - loss: 0.3075 - accuracy: 0.8652\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 292s 58ms/step - loss: 0.0779 - accuracy: 0.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b91ab9c040>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Train actual model\n",
    "\n",
    "\n",
    "model = doc2vec_model()\n",
    "model.fit(padded_sequences, y, batch_size=10, epochs=2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 12s 2ms/step - loss: 0.0137 - accuracy: 0.9986\n",
      "Test Loss: 0.013695603236556053\n",
      "Test Accuracy: 0.9985600113868713\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "results = model.evaluate(padded_sequences, y, batch_size=10)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", results[0])\n",
    "print(\"Test Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_txt_files(directory_path):\n",
    "    file_contents = []\n",
    "\n",
    "    # Iterate over each file in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            \n",
    "            # Read the content of the file and append it to the list\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                file_contents.append(content)\n",
    "\n",
    "    return file_contents\n",
    "\n",
    "pos_list = read_txt_files('pos')\n",
    "neg_list = read_txt_files('neg')\n",
    "\n",
    "# Replace 'your_directory_path' with the path to your directory containing .txt files\n",
    "list_of_strings = pos_list + neg_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list_bin = [1 for i in list(range(12500))]\n",
    "neg_list_bin = [0 for i in list(range(12500))]\n",
    "\n",
    "\n",
    "# Replace 'your_directory_path' with the path to your directory containing .txt files\n",
    "list_of_strings = pos_list + neg_list\n",
    "bin_list = pos_list_bin + neg_list_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list_of_strings)\n",
    "sequences = tokenizer.texts_to_sequences(list_of_strings)\n",
    "word_index = tokenizer.word_index\n",
    "padded_test = pad_sequences(sequences, maxlen=2493)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_list = pd.Series(bin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(padded_sequences))\n",
    "print(type(y))\n",
    "\n",
    "print(type(padded_test))\n",
    "print(type(bin_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test: (25000, 2493)\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2116 - accuracy: 0.5656\n",
      "Test Loss: 1.211595058441162\n",
      "Test Accuracy: 0.5656399726867676\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "# Assuming X_test is the input data\n",
    "print(\"Shape of X_test:\", padded_test.shape)\n",
    "results = model.evaluate(padded_test, bin_list, batch_size=10)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", results[0])\n",
    "print(\"Test Accuracy:\", results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
